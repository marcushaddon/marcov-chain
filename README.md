# marcov-chain
A class library from implementing Markov Chains
